#!/usr/bin/env python

__doc__ = "a script that lives persistently and records Monte-Carlo samples of the VT integral"
__author__ = "Reed Essick (reed.essick@ligo.org)"

#-------------------------------------------------

import os

import logging
from logging.handlers import TimedRotatingFileHandler

import numpy as np

from argparse import ArgumentParser

### non-standard libraries
from exposure import datafind
from exposure import utils
from exposure import montecarlo

from skymap_statistics import detector_cache

from gw_event_gen import eventgen

#-------------------------------------------------

DEFAULT_SNR_THRESHOLD = 8.

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

parser.add_argument('population', type=str,
    help='the population specification config used to genreate Monte-Carlo samples. \
This includes things like mass, spin, and redshift distributions, although we will \
dynamically determine the maximum redshift for detectable sources given each set of PSDs.')

parser.add_argument('-s', '--source', default=[], required=True, nargs=3, type=str, action='append',
    help='a source of PSDs. This can be repeated to specify multiple IFOs. eg, "--source IFO rootdir tag')
parser.add_argument('--snr-threshold', default=DEFAULT_SNR_THRESHOLD, type=float,
    help='the network SNR threshold for detection. Used within gw_event_gen.eventgen.Pdet to determine the probability of detecting a signal')

parser.add_argument('-r', '--require', default=[], type=str, action='append',
    help='require the PSD from this IFO to be present. Can be repeated to require multiple IFOs')
parser.add_argument('--min-num-present', default=1, type=int,
    help='the minimum number of PSDs that must be present to process a stride')

parser.add_argument('--stride', default=datafind.DEFAULT_STRIDE, type=int,
    help='the stride over which PSDs are cacluated. **NOTE**, this must match the stride with which all PSDs are generated.')
parser.add_argument('--delay', default=datafind.DEFAULT_DELAY, type=int,
    help='the amount we stay behind realtime within the persistent loop')
parser.add_argument('--max-latency', default=datafind.DEFAULT_MAX_LATENCY, type=float,
    help='the maximum latency tolerated before jumping to the current time within the loop')
parser.add_argument('--cadence', default=datafind.DEFAULT_CADENCE, type=float,
    help='the amount of time we wait between I/O queries to find frames')

parser.add_argument('-N', '--min-num-samples', default=montecarlo.DEFAULT_MIN_NUM_SAMPLES, type=int,
    help='the minimum number of Monte-Carlo samples to be generated for each stride, independent of the "smart" termination condition')
parser.add_argument('-f', '--fractional-systematic-error', default=montecarlo.DEFAULT_ERROR, type=float,
    help='the desired fractional systematic error expected from the Monte-Carlo integral for VT based on Farr (2019): arXiv:1904.10879. \
If not specified, we will only be limitted by --min-num-samples. \
**NOTE**, we assume zero observations (Nobs=0) in the derrived expressions, which will only scale the actual fractional systematic error \
approximately linearly with the actually number of observaitons.')

parser.add_argument('-v', '--verbose', default=False, action='store_true')

parser.add_argument('--gpsstart', type=float, default=None)
parser.add_argument('--gpsstop', type=float, default=None)

parser.add_argument('--output-dir', default='.', type=str)
parser.add_argument('--tag', default='', type=str)

args = parser.parse_args()

assert args.min_num_present >= 1, 'must require at least 1 PSD to be present'

if args.gpsstart is None:
    args.gpsstart = int(datafind.tconvert())

if args.gpsstop is None:
    args.gpsstop = np.infty

if args.tag:
    args.tag = "_"+args.tag

args.source = [(ifo, rootdir, '_'+tag, ifo in args.require) for ifo, rootdir, tag in args.source]

if not os.path.exists(args.output_dir):
    os.makedirs(args.output_dir)

#------------------------

for ifo, _, _, _ in args.source:
    assert ifo in detector_cache.detectors, 'ifo=%s not a known detector! known detectors are %s'%(ifo, ', '.join(detector_cache.detectors.keys()))

#-------------------------------------------------

### set up logger
logdir = os.path.join(args.output_dir, 'log')
if not os.path.exists(logdir):
    os.makedirs(logdir)

logname = os.path.basename(__file__)+args.tag
logpath = os.path.join(logdir, logname+'.log')

logger = logging.getLogger(logname)
logger.setLevel(10)

handlers = [
    TimedRotatingFileHandler(logpath, when='D', utc=True)
]
if args.verbose:
    handlers.append( logging.StreamHandler() )

formatter = logging.Formatter('%(asctime)s | %(name)s : %(levelname)s : %(message)s')
for handler in handlers:
    handler.setFormatter(formatter)
    logger.addHandler(handler)

#-------------------------------------------------

### read in population specification
logger.info('reading in population specifications from: '+args.population)
generator, timedistribution = montecarlo.path2generator(args.population)

### add AttributeTransformation for Pdet
network = detector_cache.Network() # declare this shared reference here
celest2geo = False
for trans in generator._transforms:
    if isinstance(trans, eventgen.Pdet):
        raise RuntimeError('please do not specify Pdet within %s; this will be instantiated separately'%args.population)
    celest2geo += isinstance(trans, eventgen.Celestial2Geographic)
if not celest2geo:
    generator.append_transform(eventgen.Celestial2Geographic())
generator.append_transform(eventgen.Pdet(network, snr_thr=args.snr_threshold)) ### this must come after the rest of the transforms

#-------------------------------------------------

### set up logger templates
infotmp = 'processing data within [%d, %d).'

psdtmp = 'searching for PSD for %s with rootdir=%s, tag=%s'
psdtmps = dict((ifo, psdtmp%(ifo, rootdir, tag) + ' within [%d, %d).') for ifo, rootdir, tag, _ in args.source)

updatetmp = 'updating PSD for %s from %s for data within [%d, %d).'

timeouttmp = 'latency exceeded maximum value (%.3f sec) while searching for PSD from %s!'
timeouttmps = dict((ifo, timeouttmp%(args.max_latency, ifo)+' Skipping data within [%d, %d).') for ifo, _, _, _ in args.source)

missingtmp = 'found fewer than %d PSDs.'%args.min_num_present + ' Skipping data within [%d, %d).'
foundtmp = 'found PSDs for %d IFOs (%s) within [%d, %d).'
requiredtmp = 'PSD for %s required but not found. Skipping data within'
requriedtmp = dict((ifo, requiredtmp%ifo +' [%d, %d).') for ifo, _, _, _ in args.source)

durtmp = 'updating TimeDistribution to reflect current stride: [%d, %d).'
limittmp = 'determining appropriate maximum horizon distance for data within [%d, %d).'
montetmp = 'Monte-Carlo sampling VT integral to fractional precision of %.3e with at least %d samples'%\
    (args.fractional_systematic_error, args.min_num_samples) + ' for data within [%d, %d).'

sampleswritetmp = 'writing samples to %s for data within [%d, %d).'
latencytmp = 'latency=%.3f sec for data within [%d, %d).'

### enter persistent loop
logger.info('entering persistent loop')
current = (args.gpsstart // args.stride)*args.stride
while current < args.gpsstop:
    future = current + args.stride
    tup = (current, future)
    logger.info(infotmp%tup)

    ### search for PSDs for this stride
    # remove all detectors from the network, adding back in only those that are present
    for det in network._instr:
        network.remove(det)

    datafind.wait(future, delay=args.delay, logger=logger)
    for ifo, rootdir, tag, required in args.source:
        psdpath = utils.psd_path(rootdir, tag, current, args.stride)
        logger.info(psdtmps[ifo]%tup)
        if os.path.exists(psdpath):
            logger.info(updatetmp%((ifo, psdpath,)+tup))
            freqs, psd = utils.retrieve_psd(psdpath) ### read from disk
            det = detector_cache.detectors[ifo]
            det.psd.update(psd, freqs=freqs) ### update object in place 
            network.add(det) ### append object to list of dectors for which we found data

        else:
            while datafind.latency(current, delay=args.delay) < args.max_latency:
                if os.path.exists(psdpath):
                    logger.info(updatetmp%((ifo, psdpath,)+tup))
                    freqs, psd = utils.retrieve_psd(psdpath) ### read from disk
                    det = detector_cache.detectors[ifo]
                    det.psd.update(psd, freqs=freqs) ### update object in place 
                    network.add(det) ### append object to list of dectors for which we found data
                    break
                else:
                    datafind.sleep(args.cadence)

            else:
                logger.warn(timeouttmps[ifo]%tup)
                if required:
                    logger.warn(requiredtmp[ifo]%tup)
                    current = future
                    break

    else: ### did not break because of a missing required PSD
        if len(network._instr) < args.min_num_present:
            logger.warn(missingtmp%tup)
            current = future ### bump to next stride
            continue

        # Note: we can only get here if we have at least one active detector
        logger.info(foundtmp%((len(network), ', '.join(network._instr))+tup))

        ### generate Monte-Carlo samples of VT
        logger.info(durtmp%tup)
        timedistribution._t0 = current
        timedistribution._dur = args.stride

        logger.info(limittmp%tup)
        generator.update_max_redshift(network)

        logger.info(montetmp%tup)
        for event in generator.generate_events(min_num_samples=args.min_num_samples, error=args.fractional_systematic_error):
            pass

        ### FIXME: eventually, delegate to eventgen I/O libraries for this
        attrs = [(attr, 'S50' if attr=='approximant' else 'float') for attr in sorted(generator.attributes)+sorted(eventgen.Event._waveattrs)]
        samples = np.array(
            [tuple(getattr(event, attr) for attr, _ in attrs)+(generator.pdf(event),) for event in generator._events],
            dtype=attrs+[('pdf', float)],
        )

        ### write samples
        samplespath = utils.samples_path(args.output_dir, args.tag, current, args.stride)
        thatdir = os.path.dirname(samplespath)
        if not os.path.exists(thatdir):
            os.makedirs(thatdir)
        logger.info(sampleswritetmp%((samplespath,)+tup))

        utils.report_samples(samplespath, samples)

        ### get rid of samples
        generator.flush()

        ### increment to the next stride
        logger.info(latencytmp%((datafind.latency(current, delay=args.delay),)+tup))
        current = future
